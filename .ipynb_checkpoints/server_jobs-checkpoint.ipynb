{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A job scheduling environment for allocate the jobs to machines\n",
    "import numpy as np\n",
    "import numbers\n",
    "import random\n",
    "import functools, operator\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "from collections import Counter\n",
    "class Job(object):\n",
    "  # A job class that denotes the job processed by the machine/server\n",
    "  def __init__(self, job_type, intensity):\n",
    "    if job_type not in ['CPU', 'IO']:\n",
    "      raise ValueError(\"Undefined type of job, \"\n",
    "                       \"only 'CPU' or 'IO' are allowed\")\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        job_type: 'CPU' or 'IO', either it's CPU intensive or IO intensive;\n",
    "        intensity: the computational requirement of the job, for example, \n",
    "            the average MIPS needed to accomplish the job.\n",
    "    \"\"\"\n",
    "    self.__name__ = 'Job'\n",
    "    self._type = job_type\n",
    "    self._intensity = intensity\n",
    "    \n",
    "  def get_type(self):\n",
    "    return self._type\n",
    "  \n",
    "  def get_intensity(self):\n",
    "    return self._intensity\n",
    "  \n",
    "  def info(self):\n",
    "    info = {'type': self._type, 'intensity': self._intensity}\n",
    "    return info\n",
    "  \n",
    "  def server_time_estimate(self, servers):\n",
    "    if type(servers) == Server:\n",
    "      servers = [servers]\n",
    "    server_times = []\n",
    "    for server in servers:\n",
    "      if self._type == 'CPU':\n",
    "        exec_time = self._intensity / server.get_cpu_power()\n",
    "      else:\n",
    "        exec_time = self._intensity / server.get_io_power()\n",
    "      server_times.append(exec_time)\n",
    "    return server_times\n",
    "\n",
    "class Server(object):\n",
    "  # A server object that contains the info of a server used to \n",
    "  # process the give jobs\n",
    "  def __init__(self, cpu_power, io_power):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        cpu_power: the computationa power of the server while it's working \n",
    "            on the cpu intensive tasks. In here, it's the MIPS per second\n",
    "            that the server can excute.\n",
    "        io_power: the computational power of the server when working with\n",
    "            the io intensive tasks.\n",
    "    \"\"\"\n",
    "    self.__name__ = 'Server'\n",
    "    self._cpu_power = cpu_power\n",
    "    self._io_power = io_power\n",
    "    if cpu_power >= io_power:\n",
    "      self._type = 'CPU'\n",
    "    else:\n",
    "      self._type = 'IO'\n",
    "  \n",
    "  def get_type(self):\n",
    "    return self._type\n",
    "  \n",
    "  def get_cpu_power(self):\n",
    "    return self._cpu_power\n",
    "  \n",
    "  def get_io_power(self):\n",
    "    return self._io_power\n",
    "  \n",
    "  def info(self):\n",
    "    info = {'type': self._type, \n",
    "            'cpu_power': self._cpu_power, \n",
    "            'io_power': self._io_power}\n",
    "    return info\n",
    "  \n",
    "  def job_time_estimate(self, jobs):\n",
    "    # The argument jobs should either be a single job or a list of jobs.\n",
    "    # This will return the total excution time of the give jobs\n",
    "    if type(jobs) == Job:\n",
    "      jobs = [jobs]\n",
    "    if type(jobs) == list:\n",
    "      if type(jobs[0]) != Job:\n",
    "        raise TypeError(\"The input jobs are not valid!\")\n",
    "    total_cpu_intenstity = 0\n",
    "    total_io_intensity = 0\n",
    "    for job in jobs:\n",
    "      if job.get_type() == 'CPU':\n",
    "        total_cpu_intenstity += job.get_intensity()\n",
    "      else:\n",
    "        total_io_intensity += job.get_intensity()\n",
    "    total_exec_time = (total_cpu_intenstity / self._cpu_power + \n",
    "                       total_io_intensity / self._io_power)\n",
    "    return total_exec_time\n",
    "\n",
    "\n",
    "class Generator(object):\n",
    "  # the Generator object is used to generate a given number of objects, the\n",
    "  # object being generated must have a __name__ attribute.\n",
    "  def __init__(self, object_prototype, init_params_range):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        object_prototype: a prototype of the object to be generated;\n",
    "        number_of_objects: the number of objects to generate;\n",
    "        init_params_range: a dict contains the range of every param used to initialize \n",
    "        the object, the key should be the name of the paramater, the value of each key \n",
    "        should either be a list (for non-numerical type) or a tuple (the lower and \n",
    "        upper bound of the numerical type)\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    self._ob_proto = object_prototype\n",
    "    self._params_range = init_params_range\n",
    "    \n",
    "  def generate(self, num_to_generate, method='random'):\n",
    "    # 'method' argument only works on the numerical objects\n",
    "    objects = []\n",
    "    for i in range(num_to_generate):\n",
    "      init_params = self.build_params(method=method)\n",
    "      objects.append( self._ob_proto(**init_params) )\n",
    "    return objects\n",
    "    \n",
    "  def build_params(self, method='random'):\n",
    "    init_params = {}\n",
    "    for param_name, param_range in self._params_range.items():\n",
    "      if type(param_range) == list:\n",
    "        param = random.sample(param_range, 1)[0]\n",
    "      elif type(param_range) == tuple:\n",
    "        low, upp = param_range\n",
    "        param = random.uniform(low, upp)\n",
    "      else:\n",
    "        raise TypeError(\"The param range: {} is neither list nor tuple!\"\n",
    "                        .format(param_range))\n",
    "      init_params[param_name] = param\n",
    "    return init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulingEnv(object):\n",
    "  # This is the training environment of the job scheduling task\n",
    "  def __init__(self, \n",
    "               num_jobs, \n",
    "               num_servers, \n",
    "               job_gen_params,\n",
    "               server_gen_params,\n",
    "               scheduing_speed,\n",
    "               response_time_discount,\n",
    "               init_template=None, \n",
    "               init_from_template=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      num_jobs: the number of initial jobs to generate;\n",
    "      num_servers: the number of servers to generate;\n",
    "      init_template: a dictionary type parameter that serve as the template\n",
    "          of all jobs and servers;\n",
    "      init_from_template: if True, the jobs and servers will initialize from\n",
    "          init_tempalte.\n",
    "    \"\"\"\n",
    "    self._clock = 0.\n",
    "    self._num_jobs = num_jobs\n",
    "    self._job_capacity = num_jobs\n",
    "    self._num_servers = num_servers\n",
    "    self._job_generator = Generator(Job, job_gen_params)\n",
    "    self._server_generator = Generator(Server, server_gen_params)\n",
    "    self._init_template = None\n",
    "    self._schduling_speed = scheduing_speed \n",
    "    self._response_time_discount = response_time_discount\n",
    "    \n",
    "    if init_template:\n",
    "      if (len(init_template[\"job\"]) == num_jobs and \n",
    "          len(init_template[\"server\"]) == num_servers ):\n",
    "        if init_from_template:\n",
    "          self._init_template = init_template\n",
    "          self._jobs = init_template[\"job\"]\n",
    "          self._servers = init_template[\"server\"]\n",
    "    if self._init_template == None:\n",
    "      print(\"The initialization template is either None or invalid\"\n",
    "            \", the servers and jobs will be generated randomly\")\n",
    "      self._jobs = self._job_generator.generate(num_jobs)\n",
    "      self._servers = self._server_generator.generate(num_servers)\n",
    "    self._num_finished_jobs = 0\n",
    "    self._nfj_in_servers = [0] * num_servers\n",
    "    self._clock = 0. # the unit ms indicator of the running time\n",
    "    self.init_server_status() \n",
    "    self._template = {\"job\": self._jobs, \"server\": self._servers}\n",
    "    # wrap jobs as deque object\n",
    "    self._jobs = deque(self._jobs, num_jobs)\n",
    "\n",
    "    \n",
    "  def reset(self):\n",
    "    self.__init__(self._num_jobs, self._num_servers, None, None, \n",
    "                  self._schduling_speed, self._response_time_discount,\n",
    "                  init_template=self._template, init_from_template=True)\n",
    "    \n",
    "  def get_num_jobs(self):\n",
    "    return len(self._jobs)\n",
    "\n",
    "  def get_current_job(self):\n",
    "    if self._jobs:\n",
    "      return self._jobs[0]\n",
    "    else:\n",
    "      print(\"There is no unscheduled job lest\")\n",
    "      return None\n",
    "\n",
    "  def pop_current_job(self):\n",
    "    return self._jobs.popleft()\n",
    "\n",
    "  def job_exec_times(self, job):\n",
    "    return job.server_time_estimate(self._servers)\n",
    "\n",
    "  def init_server_status(self):\n",
    "    # for each server, generate a status namedtuple containing the as:\n",
    "    #     dict(\"job_que\", \"expected_idle_time\").\n",
    "    # the server_id i is assgined as i in range(num_servers) \n",
    "    # the returned object is a orderdict of all the namedtuples.\n",
    "    servers_status = []\n",
    "    for server_id, server in enumerate(self._servers):\n",
    "      servers_status.append({\"job_info_que\": deque([], self._job_capacity),\n",
    "                             \"expected_idle_time\": self._clock}\n",
    "                           )\n",
    "      self._servers_status = servers_status\n",
    "    return servers_status\n",
    "  \n",
    "  def _get_job_type_num_from_status(self, status):\n",
    "    num_cpu_type = 0\n",
    "    num_io_type = 0\n",
    "    for job_info in status[\"job_info_que\"]:\n",
    "      if job_info[\"job\"].get_type() == 'CPU':\n",
    "        num_cpu_type += 1\n",
    "      else:\n",
    "        num_io_type +=1\n",
    "    return (num_cpu_type, num_io_type)\n",
    "  \n",
    "  def get_server_status(self):\n",
    "    status_reports = []\n",
    "    for sid, status in enumerate(self._servers_status):\n",
    "      (num_cpu_type, num_io_type) = self._get_job_type_num_from_status(status)\n",
    "      status_reports.append(StatusReport(sid,\n",
    "                                         self._servers[sid].get_type(),\n",
    "                                         self._servers[sid].get_cpu_power(),\n",
    "                                         self._servers[sid].get_io_power(),\n",
    "                                         len(status[\"job_info_que\"]),\n",
    "                                         status[\"expected_idle_time\"],\n",
    "                                         num_cpu_type, num_io_type)\n",
    "                            )\n",
    "    return status_reports\n",
    "  \n",
    "  def get_overview(self, time_span):\n",
    "    total_queuing_jobs = (self._num_jobs - len(self._jobs) - \n",
    "                          self._num_finished_jobs)\n",
    "    ind_avg_res = []\n",
    "    individual_avg_res_times = self.average_response_time(time_span)\n",
    "    for i in range(self._num_servers):\n",
    "      ind_avg_res.append({i: individual_avg_res_times[i]})\n",
    "    total_response_time = sum(individual_avg_res_times)\n",
    "    avg_response_time = total_response_time / self._num_servers\n",
    "    return {\"Total jobs in server queue\": total_queuing_jobs,\n",
    "            \"Average response time of each server\": ind_avg_res,\n",
    "            \"Average response time accross all servers\": avg_response_time}\n",
    "      \n",
    "  def expected_wait_times(self):\n",
    "    # also the expected response time\n",
    "    wait_times = []\n",
    "    for server_id, status in enumerate(self._servers_status):\n",
    "      wait_times.append(max(status[\"expected_idle_time\"] - self._clock,\n",
    "                            0)\n",
    "                       )\n",
    "    return wait_times\n",
    "\n",
    "  def expected_finish_times(self, job):\n",
    "    finish_times = []\n",
    "    exec_times = self.job_exec_times(job)\n",
    "    wait_times = self.expected_wait_times()\n",
    "    for server_id, (exec_time, wait_time) in enumerate(zip(exec_times, \n",
    "                                                           wait_times)):\n",
    "      finish_times.append(exec_time + wait_time + self._clock)\n",
    "    return finish_times\n",
    "\n",
    "  def _num_queued_jobs(self, server_id):\n",
    "    return len(self._servers_status[server_id][\"job_info_que\"])\n",
    "\n",
    "  def allocale_job_to(self, server_id):\n",
    "    status = self._servers_status[server_id]\n",
    "    current_job = self._jobs.popleft()\n",
    "    wait_time = self.expected_wait_times()[server_id]\n",
    "    if self._num_queued_jobs(server_id) < 1:\n",
    "      discounted_wait_time = wait_time\n",
    "      cum_response_time = wait_time\n",
    "    else:\n",
    "      last_dwt = status[\"job_info_que\"][-1][\"cum_discounted_response_time\"]\n",
    "      last_crt = status[\"job_info_que\"][-1][\"cum_response_time\"]\n",
    "      discounted_wait_time = wait_time + (self._response_time_discount \n",
    "                                          * last_dwt)\n",
    "      cum_response_time = last_crt + wait_time\n",
    "    exec_time = self.job_exec_times(current_job)[server_id]\n",
    "    finish_time = self.expected_finish_times(current_job)[server_id]\n",
    "    self._servers_status[server_id][\"job_info_que\"].append(\n",
    "        {\"job\": current_job, \"response_time\": wait_time,\n",
    "         \"cum_response_time\": cum_response_time,\n",
    "         \"cum_discounted_response_time\": discounted_wait_time,\n",
    "         \"finish_time\": finish_time}\n",
    "        )\n",
    "    last_idle_time = self._servers_status[server_id][\"expected_idle_time\"]\n",
    "    if last_idle_time < self._clock:\n",
    "      last_idle_time = self._clock\n",
    "    self._servers_status[server_id][\"expected_idle_time\"] = (last_idle_time + \n",
    "                                                             exec_time)\n",
    "    if (finish_time - self._servers_status[server_id][\"expected_idle_time\"] \n",
    "            > 0.00000001):\n",
    "      raise ValueError(\"Mismatching finish_time and expected_idle_time at \"\n",
    "                       \"server: {}, expected_idle_time: {}, finish_time: {}\"\n",
    "                       .format(server_id, \n",
    "                               self._servers_status[server_id][\"expected_idle_time\"],\n",
    "                               finish_time))\n",
    "    reward = self._reward_fn(wait_time, exec_time, finish_time)\n",
    "    return server_id, reward\n",
    "\n",
    "  def simulate_time_past(self, time_span):\n",
    "    self._clock += time_span\n",
    "    self._server_status_updater()\n",
    "\n",
    "  def _server_status_updater(self):\n",
    "    for sid, status in enumerate(self._servers_status):\n",
    "      # like ETA, etf means expected finish time.\n",
    "      for job_info in list(status[\"job_info_que\"])[self._nfj_in_servers[sid]:]:\n",
    "        if job_info[\"finish_time\"] < self._clock:\n",
    "          # self._servers_status[sid][\"job_info_que\"].popleft()\n",
    "          self._nfj_in_servers[sid] += 1\n",
    "          self._num_finished_jobs += 1\n",
    "        else:\n",
    "          break\n",
    "\n",
    "  def average_response_time(self, time_span):\n",
    "    watching_jobs_init = int(time_span * self._schduling_speed)\n",
    "    avg_response_t = []\n",
    "    for sid, status in enumerate(self._servers_status):\n",
    "      watching_jobs = watching_jobs_init\n",
    "      num_queued_jobs = self._num_queued_jobs(sid)\n",
    "      if num_queued_jobs < watching_jobs:\n",
    "        watching_jobs = num_queued_jobs\n",
    "      if watching_jobs == 0:\n",
    "        avg_response_t.append(0)\n",
    "      else:\n",
    "        job_info_queue = list(status[\"job_info_que\"])[-watching_jobs:]\n",
    "        total_res_t = functools.reduce(\n",
    "            operator.add, map(lambda x: x[\"response_time\"], job_info_queue))\n",
    "        avg_response_t.append(total_res_t / watching_jobs)\n",
    "    return avg_response_t\n",
    "\n",
    "  def average_discounted_response(self, time_span):\n",
    "    watching_jobs_init = int(time_span * self._schduling_speed)\n",
    "    avg_dc_t = []\n",
    "    for sid, status in enumerate(self._servers_status):\n",
    "      watching_jobs = watching_jobs_init\n",
    "      num_queued_jobs = self._num_queued_jobs(sid)\n",
    "      if num_queued_jobs < watching_jobs:\n",
    "        watching_jobs = num_queued_jobs\n",
    "      if watching_jobs == 0:\n",
    "        avg_dc_t.append(0)\n",
    "      else:\n",
    "        avg_dc_t.append( list(status[\"job_info_que\"])\n",
    "                         [-1][\"cum_discounted_response_time\"]\n",
    "                         / watching_jobs)\n",
    "    return avg_dc_t\n",
    "\n",
    "  def _reward_fn(self, wait_time, exec_time, finish_time):\n",
    "    return exec_time / (wait_time + 0.00001)\n",
    "  \n",
    "  def _buildin_policy(self, observation_span):\n",
    "    return BuildInPolicy(self, observation_span)\n",
    "  \n",
    "#def _buildin_policy(self, principle='random'):\n",
    "class BuildInPolicy():\n",
    "  def __init__(self, \n",
    "               scheduling_env, \n",
    "               observation_span, \n",
    "              ):\n",
    "    self._scheduling_env = scheduling_env\n",
    "    self._action_space = scheduling_env._num_servers\n",
    "    self._action_counter = -1\n",
    "    self._observation_span = observation_span\n",
    "\n",
    "\n",
    "  def random_policy(self):\n",
    "    return random.sample(range(self._action_space), 1)[0]\n",
    "\n",
    "  def bestfit_policy(self):\n",
    "    job = self._scheduling_env.get_current_job()\n",
    "    job_type = job.get_type()\n",
    "    wait_times = self._scheduling_env.expected_wait_times()\n",
    "    servers = self._scheduling_env._servers\n",
    "    num_servers = len(servers)\n",
    "    bestfit = 0\n",
    "    while bestfit < num_servers:\n",
    "      if servers[bestfit].get_type() == job_type:\n",
    "        break\n",
    "      else:\n",
    "        bestfit += 1\n",
    "    lastest_fit = bestfit + 1\n",
    "    while lastest_fit < num_servers:\n",
    "      if servers[lastest_fit].get_type() == job_type:\n",
    "        if wait_times[lastest_fit] < wait_times[bestfit]:\n",
    "          bestfit = lastest_fit\n",
    "      lastest_fit += 1\n",
    "    if bestfit <= num_servers - 1:\n",
    "      if servers[num_servers - 1 ].get_type() != job_type:\n",
    "        bestfit = wait_times.index(min(wait_times))\n",
    "    return bestfit\n",
    "\n",
    "  def round_robin_policy(self):\n",
    "    self._action_counter += 1\n",
    "    self._action_counter %= self._action_space\n",
    "    return self._action_counter\n",
    "\n",
    "  def earlist_policy(self):\n",
    "    job = self._scheduling_env.get_current_job()\n",
    "    wait_times = self._scheduling_env.expected_wait_times()\n",
    "    return wait_times.index(min(wait_times))\n",
    "\n",
    "  def sensible_policy(self): \n",
    "    avg_response_time = ( \n",
    "        self._scheduling_env.average_discounted_response(self._observation_span)\n",
    "        )\n",
    "    offset = max(avg_response_time)\n",
    "    logits = -np.array(avg_response_time) + offset + 10\n",
    "    probs = logits / sum(logits)\n",
    "    action = np.random.choice(a=range(self._action_space), p=probs)\n",
    "    return action\n",
    "    \n",
    "class StatusReport():\n",
    "  def __init__(self, sid, server_type, cpu_power, io_power, queue_len, e_i_t,\n",
    "               num_cpu_job, num_io_job):\n",
    "    self.status = {\"Server id\": sid, \"Type\": server_type, \n",
    "                   \"CPU power\": cpu_power, \"IO power\": io_power,\n",
    "                   \"Job queue length\": queue_len, \"Expected idle time\": e_i_t,\n",
    "                   \"CPU intensive jobs\": num_cpu_job,\n",
    "                   \"IO intensive jobs\": num_io_job}\n",
    "\n",
    "  def get_status(self):\n",
    "    return self.status\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initialization template is either None or invalid, the servers and jobs will be generated randomly\n"
     ]
    }
   ],
   "source": [
    "job_params = {\"job_type\":[\"IO\", \"CPU\"], \"intensity\":(800, 1200)}\n",
    "server_params = {\"cpu_power\":(800, 1200), \"io_power\":(500, 1500)}\n",
    "env = SchedulingEnv(10000, 10, job_params, server_params, 35, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total jobs in server queue': 3217,\n",
       " 'Average response time of each server': [{0: 147.02397059100394},\n",
       "  {1: 147.47827276232965},\n",
       "  {2: 147.13006118762206},\n",
       "  {3: 147.42725092382776},\n",
       "  {4: 147.73036174843745},\n",
       "  {5: 147.8286815379872},\n",
       "  {6: 148.28295190680996},\n",
       "  {7: 147.9136968864199},\n",
       "  {8: 147.67932001895124},\n",
       "  {9: 147.86721632608567}],\n",
       " 'Average response time accross all servers': 147.6361783889475}"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "watch_time = 200\n",
    "job_in_speed = 35\n",
    "watching_jobs = watch_time * job_in_speed\n",
    "policy = env._buildin_policy(watch_time).bestfit_policy\n",
    "actions = [0] * 10\n",
    "for i in range(watching_jobs):\n",
    "  action = policy()\n",
    "  env.allocale_job_to(action)\n",
    "  actions[action] += 1\n",
    "  env.simulate_time_past(0.05)\n",
    "env.get_overview(watch_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Server id': 0, 'Type': 'CPU', 'CPU power': 981.092317378119, 'IO power': 945.0440766726667, 'Job queue length': 625, 'Expected idle time': 644.4374163502096, 'CPU intensive jobs': 543, 'IO intensive jobs': 82}\n",
      "{'Server id': 1, 'Type': 'IO', 'CPU power': 875.901052395139, 'IO power': 1444.1650541110891, 'Job queue length': 935, 'Expected idle time': 644.3026747500157, 'CPU intensive jobs': 0, 'IO intensive jobs': 935}\n",
      "{'Server id': 2, 'Type': 'CPU', 'CPU power': 1159.2339929769942, 'IO power': 790.7133156395689, 'Job queue length': 701, 'Expected idle time': 645.1315783915268, 'CPU intensive jobs': 598, 'IO intensive jobs': 103}\n",
      "{'Server id': 3, 'Type': 'IO', 'CPU power': 833.6981194987777, 'IO power': 1309.4873020961465, 'Job queue length': 839, 'Expected idle time': 644.5067836152473, 'CPU intensive jobs': 0, 'IO intensive jobs': 839}\n",
      "{'Server id': 4, 'Type': 'CPU', 'CPU power': 1044.1478907195803, 'IO power': 502.81038015227796, 'Job queue length': 592, 'Expected idle time': 645.0635006958973, 'CPU intensive jobs': 517, 'IO intensive jobs': 75}\n",
      "{'Server id': 5, 'Type': 'CPU', 'CPU power': 1160.9477835177204, 'IO power': 1138.5302017987965, 'Job queue length': 746, 'Expected idle time': 645.054233445771, 'CPU intensive jobs': 644, 'IO intensive jobs': 102}\n",
      "{'Server id': 6, 'Type': 'CPU', 'CPU power': 968.676886921691, 'IO power': 748.2912997193804, 'Job queue length': 599, 'Expected idle time': 644.484121290348, 'CPU intensive jobs': 514, 'IO intensive jobs': 85}\n",
      "{'Server id': 7, 'Type': 'IO', 'CPU power': 875.5258539122028, 'IO power': 1050.9848885179097, 'Job queue length': 675, 'Expected idle time': 644.190891506083, 'CPU intensive jobs': 0, 'IO intensive jobs': 675}\n",
      "{'Server id': 8, 'Type': 'IO', 'CPU power': 831.7873050019509, 'IO power': 860.188169584054, 'Job queue length': 555, 'Expected idle time': 644.7246490621985, 'CPU intensive jobs': 0, 'IO intensive jobs': 555}\n",
      "{'Server id': 9, 'Type': 'CPU', 'CPU power': 1160.0911892456672, 'IO power': 1016.9266148594412, 'Job queue length': 733, 'Expected idle time': 644.7008813740538, 'CPU intensive jobs': 631, 'IO intensive jobs': 102}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(env.get_server_status()[i].get_status())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
