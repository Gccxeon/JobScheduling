{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_test import env, replay_memory, collector, samplizer_\n",
    "from dqn_agent_test import agent\n",
    "from transition import Transition\n",
    "\n",
    "import trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_helper = trainer.Trainer(env, \n",
    "                               agent, \n",
    "                               collector, \n",
    "                               replay_memory,  \n",
    "                               samplizer_, \n",
    "                               Transition, \n",
    "                               10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, loss: 8.076265335083008, iterations: 500, cum_reward: -10326.821068007244\n",
      "Episode 2, loss: 6.347304344177246, iterations: 1000, cum_reward: -14164.67113218705\n",
      "Episode 3, loss: 7.057657241821289, iterations: 1500, cum_reward: -11528.806944803138\n",
      "Episode 4, loss: 5.072875022888184, iterations: 2000, cum_reward: -8845.087566144737\n",
      "Episode 5, loss: 5.063547611236572, iterations: 2500, cum_reward: -13560.258178832091\n",
      "Episode 6, loss: 7.690804958343506, iterations: 3000, cum_reward: -9215.412367366094\n",
      "Episode 7, loss: 1.573934555053711, iterations: 3500, cum_reward: -9957.192424601471\n",
      "Episode 8, loss: 4.6435160636901855, iterations: 4000, cum_reward: -11321.836922532675\n",
      "Episode 9, loss: 10.417043685913086, iterations: 4500, cum_reward: -14363.782490683578\n",
      "Episode 10, loss: 8.134593963623047, iterations: 5000, cum_reward: -15580.274259680456\n",
      "Episode 11, loss: 8.954651832580566, iterations: 5500, cum_reward: -11472.395726293835\n",
      "Episode 12, loss: 3.9699935913085938, iterations: 6000, cum_reward: -11506.581356724602\n",
      "Episode 13, loss: 9.234962463378906, iterations: 6500, cum_reward: -11759.41466856062\n",
      "Episode 14, loss: 4.482728958129883, iterations: 7000, cum_reward: -12345.136561734735\n",
      "Episode 15, loss: 3.2416563034057617, iterations: 7500, cum_reward: -17078.68465532974\n",
      "Episode 16, loss: 5.879018306732178, iterations: 8000, cum_reward: -16341.776192365658\n",
      "Episode 17, loss: 3.5862550735473633, iterations: 8500, cum_reward: -9835.290408589442\n",
      "Episode 18, loss: 6.088770866394043, iterations: 9000, cum_reward: -8833.708931895006\n",
      "Episode 19, loss: 8.29813003540039, iterations: 9500, cum_reward: -11953.527688296834\n",
      "Episode 20, loss: 8.224248886108398, iterations: 10000, cum_reward: -10555.395637100826\n",
      "Episode 21, loss: 3.663302421569824, iterations: 10500, cum_reward: -12133.552677236677\n",
      "Episode 22, loss: 8.132986068725586, iterations: 11000, cum_reward: -9018.804650104948\n",
      "Episode 23, loss: 6.762831687927246, iterations: 11500, cum_reward: -10287.787795528777\n",
      "Episode 24, loss: 8.249835014343262, iterations: 12000, cum_reward: -12253.871444611275\n",
      "Episode 25, loss: 3.533231496810913, iterations: 12500, cum_reward: -13699.906579496701\n",
      "Episode 26, loss: 8.189945220947266, iterations: 13000, cum_reward: -12054.334323282012\n",
      "Episode 27, loss: 6.954509258270264, iterations: 13500, cum_reward: -9419.40619339002\n",
      "Episode 28, loss: 10.379850387573242, iterations: 14000, cum_reward: -11606.56487466783\n",
      "Episode 29, loss: 7.146685600280762, iterations: 14500, cum_reward: -8601.990279529142\n",
      "Episode 30, loss: 6.555624961853027, iterations: 15000, cum_reward: -7436.829433491906\n",
      "Episode 31, loss: 1.8075302839279175, iterations: 15500, cum_reward: -9625.517158137081\n",
      "Episode 32, loss: 2.286646604537964, iterations: 16000, cum_reward: -8731.161485552557\n",
      "Episode 33, loss: 3.3793678283691406, iterations: 16500, cum_reward: -15706.71135185424\n",
      "Episode 34, loss: 8.00947380065918, iterations: 17000, cum_reward: -9285.703436051166\n",
      "Episode 35, loss: 5.107163429260254, iterations: 17500, cum_reward: -16150.577046658182\n",
      "Episode 36, loss: 5.076229095458984, iterations: 18000, cum_reward: -11163.407816137538\n",
      "Episode 37, loss: 3.0785365104675293, iterations: 18500, cum_reward: -10032.771124161674\n",
      "Episode 38, loss: 4.738842487335205, iterations: 19000, cum_reward: -7157.285759289072\n",
      "Episode 39, loss: 5.7732439041137695, iterations: 19500, cum_reward: -8918.273244713548\n",
      "Episode 40, loss: 10.4358549118042, iterations: 20000, cum_reward: -12670.579859235842\n",
      "Episode 41, loss: 6.155301570892334, iterations: 20500, cum_reward: -7448.313303022442\n",
      "Episode 42, loss: 3.455392837524414, iterations: 21000, cum_reward: -10207.19252368286\n",
      "Episode 43, loss: 3.0594654083251953, iterations: 21500, cum_reward: -10020.833176861684\n",
      "Episode 44, loss: 10.982510566711426, iterations: 22000, cum_reward: -14158.291102512865\n",
      "Episode 45, loss: 6.017340183258057, iterations: 22500, cum_reward: -5339.319088440263\n",
      "Episode 46, loss: 7.046156883239746, iterations: 23000, cum_reward: -9626.488797692436\n",
      "Episode 47, loss: 8.537670135498047, iterations: 23500, cum_reward: -9596.98861115578\n",
      "Episode 48, loss: 4.899240493774414, iterations: 24000, cum_reward: -12069.256372062031\n",
      "Episode 49, loss: 5.5095391273498535, iterations: 24500, cum_reward: -9245.020779026561\n",
      "Episode 50, loss: 7.175171852111816, iterations: 25000, cum_reward: -12000.866036488604\n",
      "Episode 51, loss: 5.779539108276367, iterations: 25500, cum_reward: -10492.957417418465\n",
      "Episode 52, loss: 2.1073319911956787, iterations: 26000, cum_reward: -8547.229318783404\n",
      "Episode 53, loss: 5.646099090576172, iterations: 26500, cum_reward: -12111.269498403402\n",
      "Episode 54, loss: 6.089831352233887, iterations: 27000, cum_reward: -8643.128103514038\n",
      "Episode 55, loss: 2.1392035484313965, iterations: 27500, cum_reward: -14482.582149648648\n",
      "Episode 56, loss: 2.904118776321411, iterations: 28000, cum_reward: -10598.683432705282\n"
     ]
    }
   ],
   "source": [
    "train_helper.train(400) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 1\n",
    "env.reset()\n",
    "actions = [0] * 10\n",
    "for i in range(500):\n",
    "    t = Transition(*env.step(action))\n",
    "    t = postprocessor.process(t)\n",
    "    t = preprocessor(t)\n",
    "    action = int(agent.predict(t.state))\n",
    "    actions[action] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239f397834a14cf8807e87fdbf2be6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'CPU intensive jobs',\n",
       "              'type': 'bar',\n",
       "              'uid': 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from status_render import StatusRender\n",
    "render = StatusRender(env)\n",
    "render.job_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DqnNet(\n",
       "  (_conv_net): Sequential(\n",
       "    (convolution_0): Conv1d(1, 10, kernel_size=(3,), stride=(1,))\n",
       "    (conv_ReLU_0): ReLU()\n",
       "  )\n",
       "  (_fc_net): Sequential(\n",
       "    (fully_connected_0): Linear(in_features=100, out_features=32, bias=True)\n",
       "    (fc_activation_0): ReLU()\n",
       "    (fully_connected_1): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (fc_activation_1): ReLU()\n",
       "    (final): Linear(in_features=16, out_features=10, bias=True)\n",
       "  )\n",
       "  (_rnn_net): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helper._agent._global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_helper._env.is_terminal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999890144805657"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._eps_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._eps_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = preprocessor(replay_memory.sample(1)[0]).state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999890144805657"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent._eps_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2124)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.rand(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SchedulingEnv' object has no attribute 'actions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ed12f4dcbcf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SchedulingEnv' object has no attribute 'actions'"
     ]
    }
   ],
   "source": [
    "env.ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998848773724686"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.pow(0.9, agent._eps_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(10, (1,)).view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
